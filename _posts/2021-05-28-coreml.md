---
layout: post
title: "[iOS] 👾Core ML이란?"
date: 2021-05-28 18:34:10 +0700
excerpt: Apple Developer Document로 배우는
categories: [iOS]
tags: [Documentation]
---

## 1️⃣ Overview

CoreML을 이용하여 머신러닝 모델을 앱에 통합시킬 수 있다. 

- 모든 모델에 대한 통합 표현을 제공하는 CoreML

앱이 CoreML API와 사용자 데이터를 사용하여 사용자의 디바이스 안에서 예측을 수행하고 fine-tune 모델을 학습시킬 수 있다.

<img width="70%" src="https://docs-assets.developer.apple.com/published/7e05fb5a2e/4b0ecf58-a51a-4bfa-a361-eb77e59ed76e.png">

모델은 훈련 데이터 세트에 머신러닝 알고리즘을 적용한 결과물로, 모델을 사용하여 새로운 입력 데이터 기반 결과를 예측할 수 있다. 또한 코드로 작성하기 비실용적이거나 어려운 여러 다양한 작업들을 수행할 수 있다. 사진 분류 또는 모델을 훈련시켜 픽셀 내에서 직접 특징점으롤 찾는 작업같은 것들을 예로 들 수 있다.

Xcode 내 CreateML 앱을 사용하면 인풋데이터만 이용하여 코딩없이 모델을 빌드하고 훈련할 수 있다. 훈련된 모델 포맷은 coreml 형식으로 바로 앱에 적용 가능하다.

그리고 다양한 다른 머신러닝 라이브러리를 사용하여 모델을 만든 후, CoreML 도구를 이용하면  coreml 형식으로 변환할 수 있다. 모델이 사용자의 디바이스 내에 탑재되면, 앱 내에서 해당 사용자의 데이터로 모델을 retrain하거나 fune-tuning 할 수 있다.

메모리 공간과 전력 소비를 최소화하면서 CPU, GPU, 뉴럴 엔진을 활용함으로써 디바이스 내 ML 성능을 최적화시킨다. 사용자 디바이스 내에서 하드하게 모델을 실행하면, 네트워크 연결이 필요하지 않기 때문에 사용자의 데이터를 비공개로 유지할 수 있고 앱의 응답 능력을 유지하는데에 도움이 된다.

Core ML은 도메인 별 프레임워크와 기능에 대한 foundation

지원분야

- Vision(이미지 분석)
- Natural Language(자연어 처리)
- Speech(음성 텍스트화)
- Sound Analysis(소리 분석)

Core ML 자체는 Accelerate 및 BNNS와 같은 저수준 기본 요소와 Metal Performance Shader를 기반으로 구축된다.

<img width="70%" src="https://docs-assets.developer.apple.com/published/65b8e13531/e3663268-5db4-42c9-a7f0-2114920a9f1f.png" />

## 참조

[Apple Developer Documentation - Core ML](https://developer.apple.com/documentation/coreml)
